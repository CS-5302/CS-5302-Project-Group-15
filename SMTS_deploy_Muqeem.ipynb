{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4 # assigns unique ID to documents\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.legacy.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings # Settings.embed_model = OpenAIEmbedding()\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_scripts import llm_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n",
    "\n",
    "\n",
    "# def print_like_dislike(x: gr.LikeData):\n",
    "#     print(x.index, x.value, x.liked)\n",
    "\n",
    "# def add_message(history, message):\n",
    "#     for x in message[\"files\"]:\n",
    "#         history.append(((x,), None))\n",
    "#     if message[\"text\"] is not None:\n",
    "#         history.append((message[\"text\"], None))\n",
    "#     return history, gr.MultimodalTextbox(value=None, interactive=False)\n",
    "\n",
    "# def bot(history):\n",
    "#     response = \"**That's cool!**\"\n",
    "#     history[-1][1] = \"\"\n",
    "#     for character in response:\n",
    "#         history[-1][1] += character\n",
    "#         time.sleep(0.05)\n",
    "#         yield history\n",
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     chatbot = gr.Chatbot(\n",
    "#         [],\n",
    "#         elem_id=\"chatbot\",\n",
    "#         bubble_full_width=False\n",
    "#     )\n",
    "\n",
    "#     chat_input = gr.MultimodalTextbox(interactive=True, file_types=[\"image\"], placeholder=\"Enter message or upload file...\", show_label=False)\n",
    "\n",
    "#     chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\n",
    "#     bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\n",
    "#     bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n",
    "\n",
    "#     chatbot.like(print_like_dislike, None, None)\n",
    "\n",
    "# demo.queue()\n",
    "# if __name__ == \"__main__\":\n",
    "#     demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
