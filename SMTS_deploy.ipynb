{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import importlib\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from IPython.display import Markdown\n",
    "from python_scripts import llm_rag, machine_translation, text_to_speech, whisper_setup, get_audio, utils\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import librosa\n",
    "\n",
    "# r8_Ivqc9hSVLVo3SD03jecneTB6XD6z7Ve1ScGPw\n",
    "\n",
    "# Define paths dynamically\n",
    "PATH = os.getcwd().replace('\\\\\\\\', '/')\n",
    "\n",
    "with open('symptom_list.pkl', 'rb') as f:\n",
    "    symptom_list = pickle.load(f)\n",
    "\n",
    "root_path = PATH + '\\\\Datasets\\\\MeDAL'\n",
    "audio_path = PATH + '\\\\Datasets\\\\Audio_Files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(llm_rag)\n",
    "# importlib.reload(machine_translation)\n",
    "# importlib.reload(text_to_speech)\n",
    "# importlib.reload(whisper_setup)\n",
    "# importlib.reload(get_audio)\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMTS(Query):\n",
    "    try:\n",
    "        # Process the audio input\n",
    "        file_path = 'output.wav'\n",
    "        write(file_path, data = np.array(Query[1], dtype = np.int16), rate = Query[0])\n",
    "        audio_processed = utils.preprocess_audio(file_path)\n",
    "\n",
    "        # Transcribe Query to English\n",
    "        whisper_models = [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
    "        \n",
    "        transcript = whisper_setup.transcribe_audio(audio_processed, ['tiny'])\n",
    "        text = (transcript['tiny'][2]).lower()\n",
    "        print(text)\n",
    "\n",
    "        # Regular expression pattern to match symptoms containing 'or' any symptoms from the list\n",
    "        pattern = r'\\b(?:' + '|'.join(map(re.escape, symptom_list)) + \\\n",
    "        '|'.join('(?:{}|{})'.format(re.escape(symptom.split(' or ')[0]), re.escape(symptom.split(' or ')[1])) \\\n",
    "                 for symptom in symptom_list if ' or ' in symptom) + r')\\b'\n",
    "\n",
    "        # Extract symptoms from the query\n",
    "        extracted_symptoms = re.findall(pattern, text, flags = re.IGNORECASE)\n",
    "        print(extracted_symptoms)\n",
    "\n",
    "        # Feed query into the LLM\n",
    "        models = { \n",
    "        'llama_ours': 'ubaidtariq8/llama2-med-genai', # fine tuned model\n",
    "        'llama_13b': 'a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5',\n",
    "        'mixtral': 'mistralai/mixtral-8x7b-instruct-v0.1',\n",
    "        'llama_70b': 'meta/llama-2-70b-chat:2796ee9483c3fd7aa2e171d38f4ca12251a30609463dcfd4cd76703f22e96cdf'\n",
    "        }\n",
    "\n",
    "        model = llm_rag.DocumentEmbeddingPipeline(model_version = models['mixtral'], chroma_path = root_path)\n",
    "        model.setup_environment()\n",
    "        model.prepare_documents(collection_name = \"muqeem\", joining = True, persistent = True)\n",
    "        model.embed_and_index()\n",
    "        query = ('You are a medical doctor. A patient has come to you for desperate need of help. ' +\n",
    "         'Give as accurate diagnosis as possible tinyd on the symptoms listed. ' +\n",
    "         ' '.join(extracted_symptoms) + '. Also consider the whole query ' + text + ' ' +\n",
    "         'Give also suggestions for mitigating the problem.')\n",
    "\n",
    "\n",
    "        response = model.query_data(query + ' ' + transcript['tiny'][2])\n",
    "        \n",
    "        # Translate it back to the user language\n",
    "        translated_text = machine_translation.translate_text(text = response.response, src_lang = 'en', trg_lang = transcript['tiny'][0])\n",
    "        print(translated_text)\n",
    "        # Step 5: Now speak the response in the user's language\n",
    "        audio_answer_path = audio_path + '/audio.wav'\n",
    "        text_to_speech.multilingual_text_to_speech(text = translated_text, filepath = audio_answer_path)\n",
    "        utils.sasti_harkat(audio_answer_path)\n",
    "        arr, sr = librosa.load(audio_answer_path)\n",
    "        # display(Markdown(f\"<b>{translated_text}</b>\"))\n",
    "        return text, translated_text, (sr, arr)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 411, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 69, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\gradio\\route_utils.py\", line 689, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 65, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\routing.py\", line 756, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\routing.py\", line 776, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\routing.py\", line 297, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\routing.py\", line 77, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\responses.py\", line 352, in __call__\n",
      "    await send(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 549, in send\n",
      "    raise RuntimeError(\"Response content shorter than Content-Length\")\n",
      "RuntimeError: Response content shorter than Content-Length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i have fever, headache and difficulty breathing.\n",
      "['fever', 'headache', 'difficulty breathing']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.49file/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6941ed75ed454d88b39f766dc64cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcb677a03f04163978dee3773832737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the symptoms you've described, it's possible that you may have a respiratory infection, such as bronchitis or pneumonia. These conditions can cause fever, headache, and difficulty breathing. However, these symptoms can also be associated with other serious conditions, including COVID-19. \n",
      "\n",
      "I would strongly recommend that you seek immediate medical attention. A healthcare professional can provide a more accurate diagnosis by conducting a physical examination and possibly ordering tests. \n",
      "\n",
      "In the meantime, there are steps you can take to alleviate your symptoms. These include:\n",
      "\n",
      "1. Rest and drink plenty of fluids to stay hydrated.\n",
      "2. Over-the-counter medications, such as acetaminophen or ibuprofen, can help reduce fever and alleviate pain.\n",
      "3. If you're having trouble breathing, use a humidifier to add moisture to the air, which can help ease your symptoms.\n",
      "4. Avoid smoking and exposure to secondhand smoke.\n",
      "5. If your symptoms worsen or if you're experiencing severe difficulty breathing, seek emergency medical help immediately. \n",
      "\n",
      "Please remember that this advice is intended to be general in nature, and specific causes may not apply to your situation. Always consult with a healthcare professional for accurate information.\n",
      "Detected language: en\n",
      "Speech saved to c:\\Users\\Admin\\OneDrive\\Documents\\GitHub\\CS-5302-Project-Group-15\\Datasets\\Audio_Files/audio.wav\n"
     ]
    }
   ],
   "source": [
    "# Launch the Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn = SMTS,\n",
    "    inputs = [gr.Audio(label = 'Get your Voice Heard! ðŸ”', sources = [\"microphone\"])],\n",
    "    outputs = [gr.Textbox(label = \"We have heard your Voice! ðŸ‘‚\"), gr.Textbox(label = \"This is what we recommend: ðŸ“‹\"), gr.Audio(label = 'Press Play to listen to your medical report: ðŸ”Š')],\n",
    "    allow_flagging = 'never',\n",
    "    theme = 'gradio/base',\n",
    "    title = '''SymptoCare ðŸ¤–''',\n",
    "    description = '''## Welcome to SymptoCare! ðŸŒŸ\n",
    "    Discover the power of seamless communication in healthcare with SymptoCare, your personalized healthcare assistant!\n",
    "    ### How It Works:\n",
    "    1. ðŸŽ¤ *Speak your symptoms.*\n",
    "    2. ðŸ”„ *Let SymptoCare translate them into actionable insights.*\n",
    "    3. ðŸ—¨ï¸ *Engage with your healthcare provider like never before!*''',\n",
    "\n",
    "    article = '''### What We Offer:\n",
    "    - ðŸ—£ï¸ *Breaking language barriers with ease.*\n",
    "    - ðŸ“² *Translating your symptoms into accurate diagnoses.*\n",
    "    - ðŸ¤ *Empowering your healthcare journey with personalized care.*\n",
    "\n",
    "    ### Join Us Today:\n",
    "    Get started now and take control of your healthcare journey! Check our [Github](https://github.com/CS-5302/CS-5302-Project-Group-15) here! Do give us a star if you like our work! ðŸ˜€'''\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
